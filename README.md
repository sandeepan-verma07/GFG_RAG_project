# ğŸ§  Multi-User RAG Chatbot (PDF + Web + Memory)

This project is a **production-style Retrieval Augmented Generation (RAG) chatbot** built with **Streamlit**, **Qdrant**, **Tavily**, **Mem0**, and **Gemma 3**.

It supports:
- PDF-based question answering
- Automatic web search fallback
- Persistent long-term user memory
- Multi-user isolation using tenant IDs
- Strict context-controlled LLM responses (no hallucination)

---

## ğŸš€ Key Features

- **RAG with PDFs + Web**
- **Chunk size:** 800  
- **Chunk overlap:** 200
- **Vector DB:** Qdrant (Cosine similarity)
- **Web Search:** Tavily
- **Similarity threshold:** 0.35
- **LLM:** Gemma-3-4B-IT
- **Long-term memory:** Mem0
- **Multi-user support:** Device ID / Custom ID
- **Frontend:** Streamlit

---

## ğŸ§± Tech Stack

- Python
- Streamlit
- Qdrant
- Tavily Search
- Mem0
- Google Gemma 3
- LangChain
- Sentence Transformers
- FastEmbed
- ChromaDB (offline ingest pipeline)

---

## ğŸ§  High-Level Architecture

User Query
â†“
Embed Query
â†“
Qdrant Vector Search (PDFs)
â†“
Similarity Check (threshold = 0.35)
â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Score < 0.35? â”‚â”€â”€ Yes â”€â”€â–º Tavily Web Search
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ No
â†“
Merge PDF + Web Context
â†“
Fetch User Memories (Mem0)
â†“
Inject Recent Chat History
â†“
Gemma 3 LLM
â†“
Answer
â†“
Save Memory to Mem0 
---

## ğŸ“ Project Structure
.
â”œâ”€â”€ main.py # Streamlit app
â”œâ”€â”€ init_qdrant.py # Qdrant collection initialization
â”œâ”€â”€ qdrant_operations.py # Qdrant CRUD + search
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ embeddings.py # Embedding manager
â”‚ â”œâ”€â”€ loader.py # PDF loading & chunking
â”‚ â”œâ”€â”€ llm_gemma.py # Gemma 3 LLM wrapper
â”‚ â”œâ”€â”€ mem0_client.py # Mem0 memory handling
â”‚ â”œâ”€â”€ rag_core.py # RAG orchestration logic
â”‚ â”œâ”€â”€ retriever.py # Chroma retriever (offline)
â”‚ â””â”€â”€ vectore_store.py # Chroma vector store
â”œâ”€â”€ ingest.py # Offline PDF ingest pipeline
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ data/ # PDFs for offline ingest

---

## ğŸ§© Detailed Workflow

### 1ï¸âƒ£ User Identification (Multi-Tenant)

Each user is assigned:
- An auto-generated **Device ID**, or
- A manually entered **Custom ID (8 characters)**

This ID is used for:
- Qdrant filtering
- Mem0 memory scoping
- Chat history isolation

---

### 2ï¸âƒ£ PDF Upload & Chunking

- PDFs are split using:
  - **Chunk size:** 800
  - **Overlap:** 200
- Metadata preserved:
  - filename
  - page number
  - chunk index

---

### 3ï¸âƒ£ Embedding Generation

- Model: `sentence-transformers/all-MiniLM-L6-v2`
- Output dimension: **384**
- Same model used for:
  - PDF chunks
  - User queries

---

### 4ï¸âƒ£ Vector Storage

#### ğŸ”¹ Qdrant (Main App)
- Single collection
- Multi-tenant using `user_id`
- Payload-indexed
- Used for interactive chat

Each vector payload contains:
user_id, doc_id, filename, page, chunk_index, text

#### ğŸ”¹ ChromaDB (Offline Pipeline)
- Used by `ingest.py`
- Local persistent storage
- Converts cosine distance â†’ similarity

---

### 5ï¸âƒ£ Retrieval Logic (Hybrid RAG)

**Similarity Threshold:** `0.35`

| Mode | Behavior |
|----|----|
| PDF only | Qdrant only |
| Web only | Tavily only |
| Hybrid | Qdrant â†’ Tavily fallback |

**Fallback Rule:**
- If no PDF results
- OR top similarity < 0.35  
â†’ Tavily Web Search is triggered

---

### 6ï¸âƒ£ Tavily Web Search

- Top 3 results
- Filtered for:
  - Country relevance
  - Time relevance (current year logic)
- Used only when PDF context is weak

---

### 7ï¸âƒ£ Memory System (Mem0)

#### Long-Term Memory
- Stores conversation messages
- Scoped per `user_id`
- Used **only for personal information**

#### Memory Retrieval Trigger
Memories are fetched only if query contains:
my, me, I, remember

---

### 8ï¸âƒ£ RAG Core Orchestration

The RAG core:
1. Extracts readable text from:
   - Qdrant chunks
   - Tavily snippets
2. Fetches user memories from Mem0
3. Injects recent chat history
4. Calls the LLM

---

### 9ï¸âƒ£ LLM â€“ Gemma 3

**Model:** `gemma-3-4b-it`

#### Strict Context Priority
1. Recent chat history  
2. Long-term memories  
3. PDF context  
4. Web search results  

#### Safety Rules
- âŒ No hallucination
- âŒ No guessing personal info
- âŒ No external knowledge
- âœ… Web results override PDFs when relevant
- âœ… Time-sensitive questions rely on web only

---
